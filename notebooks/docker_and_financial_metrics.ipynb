{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7089d05",
   "metadata": {},
   "source": [
    "# Jupyter Notebook: Docker Setup and Financial Metrics Exploration\n",
    "This notebook provides a step-by-step guide for setting up Docker to containerize the project and explores financial metrics computation using PySpark and Delta Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables if .env file exists\n",
    "try:\n",
    "    load_dotenv()\n",
    "except:\n",
    "    print(\"No .env file found, using default paths\")\n",
    "\n",
    "# Define data paths using environment variables or defaults\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\", \"data\")\n",
    "CLEANED_DELTA_TABLE_PATH = os.getenv(\"CLEANED_DELTA_TABLE_PATH\", os.path.join(DATA_DIR, \"delta_tables/cleaned_tech_stocks\"))\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(CLEANED_DELTA_TABLE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd934f",
   "metadata": {},
   "source": [
    "# Setup Dockerfile\n",
    "Write a Dockerfile to containerize the project, including dependencies and environment setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbe9cd",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "# Use the official Python image as the base image\n",
    "FROM python:3.12-slim\n",
    "\n",
    "# Set the working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the requirements file into the container\n",
    "COPY requirements.txt ./\n",
    "\n",
    "# Install dependencies\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy the entire project into the container\n",
    "COPY . .\n",
    "\n",
    "# Expose the port for the Streamlit app\n",
    "EXPOSE 8501\n",
    "\n",
    "# Command to run the Streamlit app\n",
    "CMD [\"streamlit\", \"run\", \"src/streamlit_dashboard.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c662e2",
   "metadata": {},
   "source": [
    "# Build Docker Image\n",
    "Use the `docker build` command to create a Docker image for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec81492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Docker image\n",
    "import os\n",
    "\n",
    "os.system(\"docker build -t stock-market-analysis .\")\n",
    "print(\"✅ Docker image built successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de685742",
   "metadata": {},
   "source": [
    "# Run Docker Container\n",
    "Run the Docker container using the `docker run` command, exposing necessary ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"docker run -p 8501:8501 stock-market-analysis\")\n",
    "print(\"✅ Docker container is running. Access the dashboard at http://localhost:8501.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4ade5",
   "metadata": {},
   "source": [
    "# Access the Dashboard\n",
    "Provide instructions to access the Streamlit dashboard in a web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb67b5",
   "metadata": {},
   "source": [
    "1. Open your web browser.\n",
    "2. Navigate to `http://localhost:8501`.\n",
    "3. Explore the Streamlit dashboard for stock market analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e44ed8e",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as PySpark, Delta Lake, and visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57af982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc12bbd",
   "metadata": {},
   "source": [
    "# Load Data from Delta Lake\n",
    "Load cleaned data from Delta Lake for financial metrics computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"FinancialMetrics\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\")\n",
    "    .getOrCreate())\n",
    "\n",
    "# Print the path we're trying to load\n",
    "print(f\"Loading data from {CLEANED_DELTA_TABLE_PATH}\")\n",
    "\n",
    "# Try to load the data - this may fail if the delta table doesn't exist yet\n",
    "try:\n",
    "    df = spark.read.format(\"delta\").load(CLEANED_DELTA_TABLE_PATH)\n",
    "    df.show(5)\n",
    "    print(f\"Successfully loaded data with {df.count()} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading delta table: {e}\")\n",
    "    print(\"You may need to run the data processing pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84a585",
   "metadata": {},
   "source": [
    "# Compute Financial Metrics\n",
    "Calculate metrics like RSI, Moving Averages, and Sharpe Ratio using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5500690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, stddev, lag, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Define a window specification\n",
    "window_spec = Window.partitionBy(\"Ticker\").orderBy(\"Date\")\n",
    "\n",
    "# Compute Moving Average (20-day)\n",
    "df = df.withColumn(\"MA_20\", avg(\"Close\").over(window_spec.rowsBetween(-19, 0)))\n",
    "\n",
    "# Compute RSI (Relative Strength Index)\n",
    "df = df.withColumn(\"Change\", col(\"Close\") - lag(\"Close\", 1).over(window_spec))\n",
    "df = df.withColumn(\"Gain\", when(col(\"Change\") > 0, col(\"Change\")).otherwise(0))\n",
    "df = df.withColumn(\"Loss\", when(col(\"Change\") < 0, -col(\"Change\")).otherwise(0))\n",
    "df = df.withColumn(\"Avg_Gain\", avg(\"Gain\").over(window_spec.rowsBetween(-13, 0)))\n",
    "df = df.withColumn(\"Avg_Loss\", avg(\"Loss\").over(window_spec.rowsBetween(-13, 0)))\n",
    "df = df.withColumn(\"RS\", col(\"Avg_Gain\") / col(\"Avg_Loss\"))\n",
    "df = df.withColumn(\"RSI\", 100 - (100 / (1 + col(\"RS\"))))\n",
    "\n",
    "# Compute Sharpe Ratio\n",
    "df = df.withColumn(\"Daily_Return\", (col(\"Close\") - lag(\"Close\", 1).over(window_spec)) / lag(\"Close\", 1).over(window_spec))\n",
    "df = df.withColumn(\"Mean_Return\", avg(\"Daily_Return\").over(window_spec.rowsBetween(-19, 0)))\n",
    "df = df.withColumn(\"Std_Dev_Return\", stddev(\"Daily_Return\").over(window_spec.rowsBetween(-19, 0)))\n",
    "df = df.withColumn(\"Sharpe_Ratio\", col(\"Mean_Return\") / col(\"Std_Dev_Return\"))\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac046e3",
   "metadata": {},
   "source": [
    "# Visualize Financial Metrics\n",
    "Create visualizations for the computed metrics using libraries like Matplotlib or Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame for visualization\n",
    "pandas_df = df.select(\"Date\", \"Ticker\", \"Close\", \"MA_20\", \"RSI\", \"Sharpe_Ratio\").toPandas()\n",
    "\n",
    "# Plot Moving Average\n",
    "fig_ma = px.line(pandas_df, x=\"Date\", y=\"MA_20\", color=\"Ticker\", title=\"20-Day Moving Average\")\n",
    "fig_ma.show()\n",
    "\n",
    "# Plot RSI\n",
    "fig_rsi = px.line(pandas_df, x=\"Date\", y=\"RSI\", color=\"Ticker\", title=\"RSI (Relative Strength Index)\")\n",
    "fig_rsi.show()\n",
    "\n",
    "# Plot Sharpe Ratio\n",
    "fig_sharpe = px.line(pandas_df, x=\"Date\", y=\"Sharpe_Ratio\", color=\"Ticker\", title=\"Sharpe Ratio\")\n",
    "fig_sharpe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5dffaa",
   "metadata": {},
   "source": [
    "# Insights and Observations\n",
    "Analyze the visualizations and provide insights into the financial metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8239679",
   "metadata": {},
   "source": [
    "- **Moving Average**: The 20-day moving average smooths out short-term fluctuations and highlights longer-term trends.\n",
    "- **RSI**: Stocks with RSI above 70 are overbought, while those below 30 are oversold.\n",
    "- **Sharpe Ratio**: A higher Sharpe Ratio indicates better risk-adjusted returns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
